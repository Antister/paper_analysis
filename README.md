# ðŸ“Š Paper Analysis

This project is a simple tool for analyzing academic data from [DBLP](dblp.org). It scrapes paper data from top-tier computer science conferences and performs a series of analyses, including:

  * **Paper Count Statistics and Visualization**: Counts the number of papers for each conference session and plots the trends in a line chart.
  * **Research Hotspot Analysis**: Extracts keywords from paper titles and generates word clouds to analyze research trends.
  * **Paper Count Prediction**: Predicts the likely number of papers to be published in the next session of the selected conferences based on historical data.

## ðŸš€ Features

  * **Parallel Data Processing**: Utilizes parallel processing in data validation, parsing, and word cloud generation to enhance efficiency.
  * **Modular Design**: The project has a clear, modular code structure, making it easy to extend and maintain.
  * **C++ Extensions**: Core computationally intensive tasks, such as word frequency calculation, are written in C++ and bound to Python using `nanobind` for improved performance.
  * **Automated Build Process**: Uses CMake and Ninja to automate the build process for C++ extension modules, simplifying development.

## âš™ï¸ Installation and Usage

### Prerequisites

  * Python \>= 3.13
  * A C++23 compatible compiler
  * CMake
  * Ninja

The Python packages required for this project are listed in the `pyproject.toml` file and include:

  * `beautifulsoup4`
  * `lxml`
  * `matplotlib`
  * `nanobind`
  * `numpy`
  * `scikit-learn`
  * `wordcloud`

### Installation Steps

1.  **Clone the project**

    ```bash
    git clone https://github.com/Antister/paper_analysis
    cd paper-analysis
    ```

2.  **Install dependencies**

    ```bash
    pip install .
    ```

### Running the Project

Run `Entry.py` to start the project. On the first run, the project will automatically download the necessary data files from the DBLP database and compile the C++ extension modules.

```bash
python Entry.py
```

The program will perform the following actions:

1.  **Build C++ Extensions**: Compiles `check.cpp` and `freq.cpp` to generate modules that can be called from Python.
2.  **Data Fetching**:
      * Downloads and unzips `dblp.xml.gz` from DBLP, along with the corresponding DTD and MD5 checksum files to ensure data integrity.
      * Scrapes HTML page data for specified conferences (default: AAAI, CVPR, ICSE) from 2020 to 2024.
3.  **Data Parsing and Validation**:
      * Parses XML and HTML files to extract paper information.
      * Cross-validates the HTML data with the XML data to ensure consistency.
4.  **Data Analysis and Visualization**:
      * Counts and plots the annual paper count trends for each conference, saving the result to the `out/` directory.
      * Extracts keywords from paper titles to generate annual word clouds, saving them to the `out/` directory.
5.  **Paper Count Prediction**: Uses a linear regression model to predict the number of papers for each conference in the next year.

## ðŸ“¦ Project Structure

```
paper-analysis/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cpp/                 # C++ core modules
â”‚   â”‚   â”œâ”€â”€ check.cpp        # Data validation module
â”‚   â”‚   â”œâ”€â”€ freq.cpp         # Word frequency statistics module
â”‚   â”‚   â”œâ”€â”€ paper.hpp        # Paper data structure definition
â”‚   â”‚   â””â”€â”€ words.hpp        # Stopwords and terminology lists
â”‚   â””â”€â”€ python/              # Main Python logic
â”‚       â”œâ”€â”€ analyse.py       # Data analysis
â”‚       â”œâ”€â”€ fetch.py         # Data fetching
â”‚       â”œâ”€â”€ main.py          # Main program
â”‚       â”œâ”€â”€ parse.py         # Data parsing
â”‚       â””â”€â”€ predict.py       # Paper count prediction
â”œâ”€â”€ Entry.py                 # Project entry point
â”œâ”€â”€ pyproject.toml           # Project configuration file
â””â”€â”€ README.md                # Project documentation
```

## ðŸ“„ License

This project is licensed under the GNU General Public License v3.0. See the `LICENSE` file for details.